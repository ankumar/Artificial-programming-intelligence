# awesome-llm-architectures

## Benchmarks & Analysis 
- [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
- [Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
- [A holistic framework for evaluating foundation models](https://crfm.stanford.edu/helm/lite/latest/)
- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- []()
- []()
- []()
- []()
- [Artificial Analysis](https://artificialanalysis.ai/)

## GPTs

### Hugging Face Chat UI
- [Chat UI](https://github.com/huggingface/chat-ui)  
  - [Hugging Face's Chat Assistants](https://huggingface.co/chat/assistants)
  - [Open source implementation of the OpenAI 'data analysis mode' (aka ChatGPT + Python execution) based on Mistral-7B](https://github.com/xingyaoww/code-act) / [Hugging Face for Chat UI, ProjectJupyter for code executor](https://chat.xwang.dev)
- [Tokenizer Playground - How different models tokenize text](https://huggingface.co/spaces/Xenova/the-tokenizer-playground)

### Vercel Generative UI
- [AI RSC Demo](https://sdk.vercel.ai/demo)
  - [Prompt Playground](https://sdk.vercel.ai/prompt) Like Chatbot Arena https://chat.lmsys.org/
  - [AI SDK](https://sdk.vercel.ai/)
  - [v0](https://v0.dev/)
  
### Scripting
- [LangChain OpenGPTs](https://github.com/langchain-ai/opengpts)
- [GPTScript](https://github.com/gptscript-ai/gptscript)
-

## Evals
- [OpenAI Evals](https://github.com/withmartian/martian-evals)
- [Yet Another Applied LLM Benchmark](https://github.com/carlini/yet-another-applied-llm-benchmark)
- [Evaluate-Iterate-Improve](https://github.com/uptrain-ai/uptrain)
- [Open-Source Evaluation for GenAI Application Pipelines](https://github.com/relari-ai/continuous-eval)  

## Standards
- [Establishing industry wide AI best practices and standards for AI Engineers](https://github.com/AI-Engineer-Foundation)
- [The Data Provenance Initiative](https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection)

## Security, Compliance & Privacy
- [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://llm-attacks.org/)
- [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs](https://chats-lab.github.io/persuasive_jailbreaker/)
- [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems)
- []()
- []()

## Articles
- [LLM App Stack aka Emerging Architectures for LLM Applications](https://github.com/a16z-infra/llm-app-stack)
- [A Guide to Large Language Model Abstractions](https://www.twosigma.com/articles/a-guide-to-large-language-model-abstractions/)
- [AI Fundamentals: Benchmarks 101](https://www.latent.space/p/benchmarks-101)
- [The Modern AI Stack: Design Principles for the Future of Enterprise AI Architectures](https://menlovc.com/perspective/the-modern-ai-stack-design-principles-for-the-future-of-enterprise-ai-architectures/)
- [AI Copilot Interfaces](https://byrnemluke.com/ideas/llm-interfaces)
- [Evaluating LLMs is a minefield](https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/)
- []()
- []()

## AI Twitter
- [@karpathy](https://twitter.com/karpathy)
- []()
- []()
- []()
- []()
- []()
- []()
- [@antirez](https://twitter.com/antirez/status/1746857737584099781)
- [@ivanfioravanti](https://twitter.com/ivanfioravanti)

## Papers
- [Large Language Models: A Survey](https://arxiv.org/abs/2402.06196)
- [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/pdf/2304.12244.pdf)
- [RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture](https://arxiv.org/abs/2401.08406)
- [Multi-line AI-assisted Code Authoring](https://huggingface.co/papers/2402.04141)
- []()
- []()

## Uncategorized
- [Stanford DSPy: The framework for programming—not prompting—foundation models](https://github.com/stanfordnlp/dspy)
-
- [Minimal, clean code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization](https://github.com/karpathy/minbpe)
- 
- [Building the open-source feedback layer for LLMs](https://github.com/argilla-io)
- []()
- []()
- [Prompt Engineering with Llama 2](https://github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb)
- [RAGStack](https://docs.datastax.com/en/ragstack/docs/index.html)
- [Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines](https://github.com/explodinggradients/ragas)
- [Easily use and train state of the art retrieval methods in any RAG pipeline. Designed for modularity and ease-of-use, backed by research](https://github.com/bclavie/RAGatouille)
- [Data Provenance Explorer](https://dataprovenance.org/)
- [SkyPilot: Run LLMs, AI, and Batch jobs on any cloud. Get maximum savings, highest GPU availability, and managed execution—all with a simple interface](https://github.com/skypilot-org)

## Learning
- [Large Language Model Course](https://github.com/mlabonne/llm-course)
- []()
- []()
